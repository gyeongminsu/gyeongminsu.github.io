---
title : 인공 지능 연구에서 관찰되는 과학적 실재론적 관점과 반실재론적 관점의 공존, 그리고 실재론적 접근의 이점 - 대형 언어 모델을 중심으로
categories : Philosophy_of_Science, Scientific_Reaslism, Scientific_AntiRealism
tags : Philosophy_of_Science, Scientific_Reaslism, Scientific_AntiRealism
date : 2025-07-01 18:00:00 +0900
pin : true
path : true
math : true
image : /assets/img/2025-07-01-POSpaper/thumbnail.webp
toc : true
layout : post
comments : true
---

# 인공 지능 연구에서 관찰되는 과학적 실재론적 관점과 반실재론적 관점의 공존, 그리고 실재론적 접근의 이점 - 대형 언어 모델을 중심으로

이 논문은 과학철학 수업에서 기말 과제로 제출해서 최고점을 받은 논문입니다.

## 1. 서론
현대 과학철학에서 "과학 이론의 목표는 실제 세계를 객관적으로 묘사하는 것인가"에 대한 논쟁은 여전히 해결되지 않고 진행되고 있는 주제 중 하나이다. 이 주제에서 주로 제기되는 견해에는 과학적 실재론과 과학적 반실재론이 있다. 과학적 실재론자는 과학 이론의 목표가 세계에 대한 참된 기술이라고 믿으며, 과학 이론이 현실 세계를 정확히 반영하고 세계의 진리에 접근하는 것이라고 주장한다. 이에 반해 과학적 반실재론자는 과학 이론의 발전이 실제 세계를 참되게 묘사하는 것과는 무관하다고 주장한다. 과학적 반실재론의 형태 중 하나인 도구주의에서는, 과학 이론이 단지 관찰 가능한 현상을 예측하고 설명하는 하나의 도구에 불과하다고 주장한다. 이러한 과학 이론의 발전에 대한 철학적 시각의 차이는 과학 이론의 목적과 의미에 대한 근본적인 이해 차이를 드러내며, 과학 발전의 성과를 어떻게 해석할지에 영향을 미치고 있다.

인공 지능 연구자들의 접근 방식에도 과학적 실재론적 접근과 반실재론적 접근이 공존한다. 실재론적인 접근은 인간 인지나 뇌의 실제 작동 원리를 모방하려는 방향이고 반실재론적인 접근은 생물학적 현실과 무관하게 상식에 대한 질의응답, 수학 및 과학, 코딩과 같은 추론 문제 [^1][^2]의 예측 정확도나 인간의 정성적 분석을 통해 판단한 성능만 높이면 된다는 입장으로 순전히 기능적 성능 위주의 연구를 추구하는 방향이다. 예를 들어, 현재 대형 언어 모델의 가장 골조로 쓰이는 Transformer의 신경망 구조는 Attention 메커니즘과 같이 인간 인지의 영향을 받은 메커니즘을 도입하면서도, 다른 한편으로는 역전파 알고리즘처럼 생물학적 현실과 떨어져 있는 메커니즘이 동시에 이용된다.[^3]본 논문에서는 이러한 대형 언어 모델의 연구 및 개발 과정에 내포된 과학적 실재론적, 반실재론적 요소들을 분석하고, 특히 인간의 인지과학적 유사성과 모델의 설명력 및 과학적 이해의 증진의 측면에서 볼 때 실재론적인 접근을 취하는 것이 반실재론적인 접근을 취하는 것보다 어떤 이점을 가지는지 논의하고자 한다.

## 2. 과학적 실재론과 반실재론
과학적 실재론은 과학 이론의 목표는 실제 세계의 객관적인 참을 밝혀내는 것이고, 과학이 발전할수록 근사적으로 세계의 실제 모습을 정확히 밝혀내고 있는 것라고 보는 견해이다. 실재론자들은 과학 이론이 세계의 참된 모습에 근접함으로써 강력한 설명력과 예측력을 발휘하는 이론이라고 주장한다. 과학적 실재론을 옹호하는 논증 중에는 기적 불가 논증(no-miracle argument)이 있다. 기적 불가 논증은 과학 이론이 정확한 예측을 성공적으로 내놓는 이유는 우연이 아니라, 과학 이론이 세계의 진리에 대해 근사적으로 참되게 묘사하기 때문이라고 주장하는 논증이다. 다시 말해, 이론이 현실 세계의 구조를 어느 정도 정확히 묘사하고 있기에 성공적인 예측을 보인다는 것이다. 왜냐하면 과학이 근사적 진리가 아닐 경우, 과학이 강력한 설명력과 예측력을 발휘하는 것은 기적에 가까울 것이라고 보기 때문이다. 따라서 기적 불가 논증은 과학의 목적이 단순한 계산적 도구의 발명이 아니라 현실에 대한 정확한 설명을 얻고 실제 모습에 다가가는 것이라는 주장에 힘을 싣게 한다.

반대로 과학적 반실재론은 과학 이론이 설령 성공적이라 해도, 그것이 현실을 참되게 묘사하고 있다는 보장이 없다고 본다. 반실재론자들은 과학의 목표는 경험적으로 타당한 설명, 즉 관찰되는 현상을 정확히 예측하는 것으로 충분하다고 주장한다. 예를 들어 전자나 중력과 같은 과학 이론의 개념들의 실존 여부는 중요하지 않으며 단지 우리의 경험을 잘 표현하고, 새로운 현상을 예측할 수 있으면 된다는 것이다.

## 3. 인공 지능 연구에서의 두 가지 관점
실재론적 접근과 반실재론적 접근의 대비는 인공 지능 연구 분야의 역사와 현재 동향에서도 발견된다. 인공 지능 모델을 연구하면서 발전시켜온 연구자들은 대체로 두 가지 접근법 사이에서 연구 방법을 택하거나 결합해 왔다.

먼저 인공 지능 모델을 통해 인간 또는 생명체의 인지 과정을 모방하려는 접근이 있다. 이는 인간 또는 생명체의 지능과 학습 원리를 규명하고 그것을 본받아 인공 지능 모델을 설계하려는 노력으로 설명할 수 있다. 예를 들어 인공 신경망(Artificial Neural Network, ANN)은 뇌신경 세포인 뉴런의 연결망을 추상화한 모델로 제안되었고, 안구와 이어진 대뇌 시각 피질의 국부 수용 영역(local receptive field)에 착안하여 인공 지능 모델의 이미지 분류 태스크에 많은 발전을 이룩했다[^4]. 이러한 접근에서는 인공 지능 모델이 실제로 인간이 인지하는 방식과 유사하게 동작하도록 만든다는 관점이 적용되었다. 궁극적으로 인간 지능의 실재하는 구조와 원리를 인공 지능 모델로 구현함으로써, 인공 지능 모델을 통해 인간의 마음과 행동을 이해하는 강인공지능(AGI)에 이르는 것을 목표로 한다. 이처럼 생물학적 혹은 인지과학적 사실을 인공 지능 모델 설계의 근거로 삼는 접근 방식은 과학적 실재론과 맞닿아 있다. 이러한 관점에서 설계한 인공 지능 모델이 설계자의 목적에 맞게 잘 작동한다면, 그것은 실제 인지 메커니즘의 일부를 포착했기 때문에 가능한 일이며, 따라서 모델의 출력 및 성과를 설명하고 해석한다고 볼 수 있다.

다른 관점에서는 순전히 실용적 성능을 최우선시하는 접근이 있다. 이 접근에서는 모델의 내부 과정이 실제 인간의 사고와 유사한지의 여부는 부차적이며, 주어진 과제에서 최고의 정확도나 바람직한 출력을 달성하는 것이 목적이다. 예시로 현재 딥러닝 모델의 주류 학습법 메커니즘인 역전파 알고리즘이 대표적이다. 역전파 알고리즘은 인간이나 다른 생명체의 뇌가 정보를 학습하는 방식과는 거리가 있지만, 인공 신경망에서 비롯한 인공 지능 모델의 효과적인 최적화를 가능하게 함으로써 인공 지능 모델의 발전을 가능케 하였다. 역전파와 같이 모델 내부의 알고리즘에서 인간의 뇌와의 유사성과 같은 생물학적 타당성보다 출력의 유용성을 최우선시하여 궁극적으로 주어진 태스크에서 최고의 정확도와 바람직한 출력만을 목표로 하는 접근은 도구주의적으로 예측을 통해 유용한 결과를 얻는 것에 목표를 두는 반실재론적 관점에 부합한다. 실제로 2010년대 딥러닝 붐을 이끈 것은 모델을 구성하는 이론의 생물학적 타당성보다 방대한 데이터와 진보된 계산 자원을 활용한 경험적 성공이였다.[^5][^6][^7] 이는 인공 지능 모델을 그 내부를 들여다볼 수 없는 블랙박스 도구로 취급하고, 결과만 좋으면 그 내부는 일종의 계산상의 편의를 도와주는 도구로 바라보는 반실재론적인 태도의 부산물이었다고 말할 수 있다.


## 4. 실재론적 접근의 가치
3장에서 살펴본 것과 같이 실재론적 관점의 접근과 반실재론적 관점의 접근 모두 인공 지능의 발전에 상보적으로 기여해온 바가 있지만, 저자는 장기적으로 대형 언어 모델을 비롯한 인공 지능 모델의 연구에서 실재론적 접근이 갖고 있는 장점과 반실재론적 관점의 접근의 부작용에 대해 주장하고자 한다. 그러한 이유를 실재론적 접근의 인지적 유사성 확보와 우수한 설명력이라는 두 가지의 축으로 정리해보고자 한다.

### 4.1. 인공 지능 모델의 인지 유사성이 주는 이점
실제 인간 및 생명체와 인지 유사성을 가진 인공 지능 모델은 뇌과학 및 인지과학에서 일방적으로 영향을 받는 것뿐만 아니라 뇌과학 및 인지과학의 발전에 영향을 주는 것도 가능해진다. 실제로 MIT와 IBM Watsons의 과학자들은 Transformer 모델의 작동 원리를 뇌의 신경 회로로 구현하는 가설을 수립하여 실험을 진행하였다[^8]. 그 결과 Transformer의 핵심 메커니즘인 Self-Attention이 실제 생물의 뇌에서는 뉴런-아교세포(Neuron-astrocyte)가 이루는 세 방향 시냅스(tripartite synapse) 구조로 구현될 가능성을 제시하고 있다. 이는 실재론적 접근을 통해 만들어진 대형 언어 모델의 알고리즘이 뇌과학의 연구 방향에 영향을 준 것이다. 더불어 이 연구성과는 다시 뇌과학에서 대형 언어 모델 구조 연구로의 방향에도 영향을 끼치는 연구로 발전하였다[^9]. 앞서 발견된 뉴런-아교세포의 구조를 응용해 더욱 발전된 Transformer 모델의 구조를 제시하는 연구로 나아간 것이다.

이러한 상호보완적인 연구를 통해 기존의 뇌과학 이론으로는 고려하지 못했던 새로운 뇌 기능에 대한 관점을 제시할 수 있게 되고, 인공 지능 모델 또한 구체적인 뇌과학 이론을 따라 설계하게 되어 모델의 성능과 학습 능력을 견고하게 향상시킬 수 있다. 만약 인공 지능 모델이 실제 뇌의 작동 방식을 추구하도록 발전하지 않았다면 상기한 인공 지능 모델과 실제 인간 인지 탐구의 쌍방향적인 발전은 이루어지지 못했을 것이다.

실재론적 관점의 연구를 통해 상이한 분야 간의 시너지를 내는 효과는 인공 지능 분야뿐 아니라 전통적인 과학 연구에서도 발견된다. 그 대표적인 예시에는 사회생물학(sociobiology)가 있다. 사회생물학은 생물학, 특히 진화생물학의 이론을 바탕으로 인간과 동물의 사회적 행동을 설명하려는 분과 학문 간의 통섭에 의해 창시되었다. 예를 들어 생물 개체의 이타적 행동, 협동, 공격성 등의 사회적 양상들을 유전자 수준의 선택 압력과 진화적 적응성이라는 진화생물학적 틀을 통해서 분석한다[^10]. 사회생물학은 이렇게 생물학적 설명을 사회현상에 접목하여, 개별 분과 학문만으로는 설명하기 어려운 문제들을 일관된 이론으로 설명하는데 공헌하였다. 이것은 동일한 실재적 대상을 생물학, 사회학의 각 분과 학문에서 다른 관점을 통해 기술하던 것을 하나의 관점으로 통합하여 설명적 일관성을 지향하게 한다.

만약 사회학과 생물학이 별개로만 연구되었다면 생물학자는 인간의 사회적 행동을 개체 수준에서 모순적인 현상으로 남겨두거나 유전자, 진화, 자연선택 등 생물학적 원리에만 제한하여 설명하려 했을 것이고, 사회학자는 인간 행동을 사회문화적 맥락, 사회구조, 상호작용, 규범 등으로만 해석하여 보편적 진화를 간과했을 것이다. 따라서 도구주의적으로 과학의 발전을 단순하게 병렬적으로 축적하는 것보다, 실재론적인 접근을 통해 분과 학문 간의 정합적인 구조를 형성하는 것이 성숙한 과학으로 나아가 과학의 설명력을 증진하는 데 중요한 역할을 한다.

### 4.2. 모델의 설명력 및 과학적 이해의 증진
과학적 실재론을 지지하는 사람들은 과학 이론이 깊은 설명을 가능하게 할수록 그 과학 이론은 진리에 가까운 성숙한 과학이라고 얘기한다. 이 견해는 실재론적 관점의 연구를 통해 인공 지능 모델을 개발해야 모델의 동작 원리에 대해 더 깊고 투명한 설명을 할 수 있다는 주장으로 연결될 수 있다. 반실재론적 관점을 통해 성능만을 위주로 개발되어 내부 구조의 투명성을 등한시한 인공 지능 모델은 원하는 태스크에서 높은 성능을 이룸에도 불구하고 “어째서 그런 결과가 나왔는지” 설명하기 어려운 경우가 많기 때문이다.

이에 반해 인공 지능 모델이 실재론적인 관점을 통해 설계될수록 인공 지능 모델은 생물학적 혹은 인지과학적 타당성을 갖추게 되면서, 모델의 동작은 더욱 이해 가능한 원리로 설명될 수 있다. 예를 들면, 대형 언어 모델이 어떤 질문에 대답할 때 “모델의 몇 번째 계층의 어떤 Attention Head가 입력 프롬프트에 대한 특정 어휘에 집중하여 이러한 출력을 형성했다”는 식의 분석이 가능해진다. 이를 통해 대형 언어 모델의 내부 작동을 인간 언어와 개념으로 옮겨 설명할 수 있게 된다.

일례로 미국의 인공지능 스타트업인 Anthropic은 자사가 만든 대형 언어 모델인 Claude 3.5 Haiku의 동작 원리를 해석하기 위한 연구를 진행하였다[^11]. Anthropic은 Claude 3.5 Haiku가 다단계 추론, 문학 작문, 다국어 번역, 수학적 계산 등에 대해 다양한 입력이 주어졌을 때 어떻게 작업을 처리하고 출력을 내는지에 대해 실제 모델을 완전히 해부하는 대신, 더 해석이 쉬운 대체 모델(Replacement Model)을 만들어 실제 모델의 동작을 근사(approximate)하여 해석하였다. Anthropic은 이러한 해석 과정을 생물학(Biology)에 빗대어 표현하였는데, 대체 모델을 이용해 특정 프롬프트에 대해 모델이 수행하는 계산 단계의 순서를 묘사하는 인과 그래프인 Attribution Graph를 분석하는 과정에서 모델과 생물 시스템 간의 유사성을 포착하여 모델을 생물학에 빗댄 표현을 사용하였다.

Attribution Graph를 관찰했을 때 Graph의 노드(Node)들과 노드간의 연결을 나타내는 엣지(Edge)의 연결을 슈퍼 노드로 그룹화하여 분석했는데, 이 분석을 통해 언어 모델의 다양한 계층에서 발견되는 특징들과 그들 간의 상호작용이 생물학적 시스템의 계층적 조직(분자, 세포, 조직 기관)과 유사한 구조를 보이고 그에 따라 생물학적 영감이 들어갔다고 설명한다.

Anthropic의 대형 언어 모델 해석 연구는 여러 한계점이 존재한다. 우선 해석하려는 모델인 Claude 3.5 Haiku 자체를 완전히 해석한 것이 아니라 근사 모델을 만들어서 해석했다는 제한이 있고, 모델의 핵심적인 계층인 Attention 메커니즘의 패턴 형성은 포착하지 못했다는 것이다. 그 이유는 원본 모델의 파라미터 크기가 너무 방대하고, 모델의 구조가 너무 복잡하기 때문이다. 이런 한계는 반실재론적 관점에서 개발된 모델일수록 더욱 심화될 위험이 있다. 성능 지상주의에 입각해 모델을 점점 크고 복잡하게 만들수록 내부를 이해하기에 점점 어려워질 것이기 때문이다. 또한 Anthropic에서 개발한 대형 언어 모델의 해석 방법론은 OpenAI의 GPT, Meta의 Llama, Google의 Gemini와 같이 다른 집단에서 개발한 언어 모델에서는 유효하게 작용하지 않을 것이다. 왜냐하면 각 언어 모델의 구조는 도구주의적인 측면에서 원하는 성능을 내기 위해 제각기 다른 구조로 만들어졌고, 이에 따라 모델의 구조를 해석하는 방법론은 달라질 것이기 때문이다. 이처럼 원본 모델의 성능 향상을 위한 도구주의적 인공 지능 모델 연구는 모델 내부 구조의 해석 가능성을 고려하지 않고 진행될 것이기 때문에 상기한 한계점을 더욱 강화할 것이다. 여기서 실재론적 관점의 연구를 진행해야 하는 이유를 찾을 수 있다. 우리는 왜 인공 지능 모델이 이렇게 행동하는지 묻고 싶어도, 모델이 복잡할수록 답을 할 수 없는 상황에 놓일 수 있다. 사실 이미 놓여져 있다. 따라서 장기적으로 볼 때, 실제 인간 지능의 이해에 이바지하기 위해서는 단순히 도구적 성취에 머무르지 않고 실재론적 관점의 연구를 지향함으로써 대형 언어 모델을 포함한 인공 지능 모델의 입출력에 대한 해석 가능성을 증진시킬 수 있다.

## 5. 결론
과학적 실재론과 반실재론의 관점은 인공 지능 연구에서 서로 다른 방향으로 나타났지만, 대형 언어 모델을 비롯한 인공 지능의 발전은 두 관점의 결합적 활용을 통해 이루어진 면이 존재한다. Attention 메커니즘의 도입과 같은 실재론적 접근은 인간 인지의 실제 작동 원리를 반영하여 모델을 연구함으로써 모델의 성능과 이해도를 높였고, 역전파 알고리즘 등의 성능을 위한 도구적 접근은 인공 지능 모델의 효과적인 학습을 통해 성능 향상을 이루어냈다. 그러나 궁극적으로 인공 지능 모델을 통해 인간 지능에 대한 과학적 이해를 제공하기 위해서는, 반실재론적인 관점에 해당하는 도구주의적 성취에 머무르지 않고 실재론적 접근의 연구를 강화할 필요가 있다.

인공 지능 모델을 단지 원하는 성능을 이루기 위한 블랙박스 모델로써 개발하는 것이 아니라, 현실의 지능에 대한 이론적 모델로 간주하고 다룰 때 우리는 더욱 인공 지능을 통해 많은 이점을 얻을 수 있다. 다시 말해, 지능이라는 현상을 이해하고자 하는 과학적 열망, 즉 실재론적인 지향이 있다면 우리는 인공 지능 연구에서도 현실을 반영하지 않은 채 성능만 추구하는 태도를 지양하고, 현실의 인지 구조에 밀착된 모델을 만들고 해석하는 방향으로 나아가야 한다.

앞으로의 연구에서는 실재론적인 관점에서의 연구 및 개발을 통해 생물학적으로 설명 가능한 학습 알고리즘이나, 인간 및 생명체의 인지 구조를 모방한 아키텍처가 개발되어 현재의 대형 언어 모델들이 가진 비현실적인 부분들을 보완해나갈 수 있을 것이다. 그렇게 된다면 대형 언어 모델을 비롯한 인공 지능 모델의 작동이 더욱 투명하게 해석 가능해지고, 인간 지능과의 연결고리도 한층 명확해져서 어떻게 모델의 출력이 나왔는지 이론적으로 설명하는 일이 자연스러워질 것이다. 우리는 인공 지능을 단순히 기술적 편의가 아닌 과학적 이해를 제공하는 도구로 만들기 위해 실재론적 접근의 중요성을 제고하여야 한다.

---
[^1]: Hendrycks, D., C. Burns, S. Kadavath, A. Arora, S. Basart, E. Tang, D. Song, & J. Steinhardt, Measuring mathematical problem solving with the MATH dataset, Adv. Neural Inf. Process. Syst. 34, https://arxiv.org/abs/2103.03874 (2021).
[^2]: Rein, D., J. Wei, E. Kolve, C. Potts, & N. Sridhar, GPQA: A graduate-level Google-proof Q&A benchmark, Proc. First Conf. Lang. Model., https://arxiv.org/abs/2311.12022 (2024).
[^3]: Vaswani, A., N. Shazeer, N. Parmar, J. Uszkoreit, L. Jones, A.N. Gomez, Ł. Kaiser, & I. Polosukhin, Attention is all you need, Adv. Neural Inf. Process. Syst. 30 (2017).
[^4]: O'Shea, K., & R. Nash, An introduction to convolutional neural networks, arXiv preprint arXiv:1511.08458, https://arxiv.org/abs/1511.08458 (2015).
[^5]: Ching, T., D.S. Himmelstein, B.K. Beaulieu-Jones, A.A. Kalinin, B.T. Do, G.P. Way, E. Ferrero, P.-M. Agapow, M. Zietz, M.M. Hoffman, W. Xie, G.L. Rosen, B.J. Lengerich, J. Israeli, J. Lanchantin, S. Woloszynek, A.E. Carpenter, A. Shrikumar, J. Xu, E.M. Cofer, C.A. Lavender, S.C. Turaga, A.M. Alexandari, Z. Lu, D.J. Harris, D. DeCaprio, Y. Qi, A. Kundaje, Y. Peng, L.K. Wiley, M.H.S. Segler, S.M. Boca, S.J. Swamidass, A. Huang, A. Gitter, & C.S. Greene, Opportunities and obstacles for deep learning in biology and medicine, J. R. Soc. Interface 15 (141) 20170387, https://doi.org/10.1098/rsif.2017.0387 (2018).
[^6]: Baraniuk, R., D. Donoho, & M. Gavish, The science of deep learning, Proc. Natl. Acad. Sci. U.S.A. 117 (48) 30029–30032, https://doi.org/10.1073/pnas.2020596117 (2020).
[^7]: Razavi, S., Deep learning, explained: Fundamentals, explainability, and bridgeability to process-based modelling, Environ. Model. Softw. 144, 105159, https://doi.org/10.1016/j.envsoft.2021.105159 (2021).
[^8]: Kozachkov, L., K.V. Kastanenka, & D. Krotov, Building transformers from neurons and astrocytes, Proc. Natl. Acad. Sci. U.S.A. 120 (34) e2219150120, https://doi.org/10.1073/pnas.2219150120 (2023).
[^9]: Kozachkov, L., J. Slotine, & D. Krotov, Neuron–astrocyte associative memory, Proc. Natl. Acad. Sci. U.S.A. 122 (21) e2417788122, https://doi.org/10.1073/pnas.2417788122 (2025).
[^10]: Wilson, E.O., Sociobiology: The new synthesis, Harvard Univ. Press (2000).
[^11]: Anthropic, On the biology of a large language model, https://transformer-circuits.pub/2025/attribution-graphs/biology.html (2025).